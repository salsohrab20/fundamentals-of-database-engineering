# ğŸ§ª PostgreSQL Partitioning Demo (Using Docker)

In this demo, we'll spin up a PostgreSQL instance using Docker ğŸ³, generate a large dataset (10 million rows ğŸ“Š), and prepare for partitioning. Letâ€™s get started!

---

## ğŸ§° Requirements

- âœ… Docker installed
- âŒ No need to install PostgreSQL manually
- âš™ï¸ All setup is done inside a Docker container

---

## ğŸ³ Step 1: Run PostgreSQL in Docker

Run the following command in your terminal:

```bash
docker run \
  --name pg-main \
  -d \
  -e POSTGRES_PASSWORD=postgres \
  postgres
```
- -name pg-main: Name your container ğŸ·ï¸
- -d: Run in detached mode ğŸ§µ
- -e POSTGRES_PASSWORD=postgres: Set the Postgres password ğŸ”
- postgres: Image name ğŸ˜

## ğŸ–¥ï¸ Step 2: Enter the Container
- Run:
```bash
docker exec -it pg-main 
````
- Then, inside the container:
```
psql -U postgres
```
- You're now inside the PostgreSQL CLI ğŸ˜.

## ğŸ—ï¸ Step 3: Create the Table

- Create a simple table to hold student grades:

```sql
CREATE TABLE grades_original (
id SERIAL NOT NULL,
g  INTEGER NOT NULL
);
```
> ğŸ¯ Note: Columns used for partitioning must be NOT NULL.

## ğŸ”„ Step 4: Insert 10 Million Rows

- Insert 10M rows with randomly generated grades (0â€“99):

```sql
INSERT INTO grades_original (g)
SELECT FLOOR(random() * 100)
FROM generate_series(1, 10000000);
```
- ğŸ§  We're using random() * 100 to simulate grades between 0 and 99, and generate_series() to produce 10 million rows.
- â³ This will take a few moments...

## ğŸ—‚ï¸ Step 5: Create an Index
- Add an index on the g column for faster query performance:
```sql
CREATE INDEX grades_original_g_idx
ON grades_original (g);
```
> ğŸ“ˆ Indexing helps speed up queries, especially when scanning/filtering rows by g.

## ğŸ§¾ Step 6: Describe the Table
- To confirm everything looks good:

```sql
\d grades_original
```
- You should see:
- id: serial, not null
- g: integer, not null
- Index: grades_original_g_idx on column g


# ğŸ” Query Performance and Execution Plans in PostgreSQL

Now that weâ€™ve inserted 10 million rows into `grades_original`, letâ€™s run some queries and understand how PostgreSQL processes them using `EXPLAIN ANALYZE`.

---

## ğŸ”¢ Query 1: Exact Match

```sql
SELECT COUNT(*) FROM grades_original WHERE g = 30;
```

## ğŸ§¾ Result:
- Around 10,000 rows match the condition g = 30.
- Fast execution due to index usage.
- ğŸ”¬ Using EXPLAIN ANALYZE:
> EXPLAIN ANALYZE SELECT COUNT(*) FROM grades_original WHERE g = 30;

## ğŸ“Š Output Insights:
- Execution Time: ~2000 ms (2 seconds) â±ï¸
- Planning Time: ~0.97 ms
- Query Plan: Bitmap Index Scan
- PostgreSQL uses the index to find matching rows quickly.
- Then it visits the actual table to retrieve the rows.

## ğŸ’¡ Bitmap Index Scan is efficient for selective queries but can become slower with high data spread.

## ğŸ”¢ Query 2: Range Query
- SELECT COUNT(*) FROM grades_original WHERE g BETWEEN 30 AND 35;
- ğŸ”¬ Using EXPLAIN ANALYZE:
> EXPLAIN ANALYZE SELECT COUNT(*) FROM grades_original WHERE g BETWEEN 30 AND 35;

## ğŸ“Š Output Insights:
- Execution Time: ~3000 ms (3 seconds) â±ï¸
- Query Plan: Parallel Index Scan
- PostgreSQL chose parallel execution to scan the index across multiple threads.
- Then it combined the results to get the final count.

> âš–ï¸ Range queries can take longer depending on the number of matching rows and how data is distributed.

## ğŸ§  Summary

| Query Type        | Index Used?           | Execution Time | Plan Type                  |
| ----------------- | --------------------- | -------------- | -------------------------- |
| `g = 30`          | âœ… Bitmap Index Scan   | \~2 sec        | Efficient for point lookup |
| `g BETWEEN 30â€“35` | âœ… Parallel Index Scan | \~3 sec        | Efficient for small ranges |

- PostgreSQL chooses different execution plans depending on the query type and data distribution.
- Even with indexes, larger data ranges or less selective queries can take longer.
- Use EXPLAIN ANALYZE to understand and optimize your queries.

# ğŸ§ª PostgreSQL Partitioning Demo

## ğŸ¯ Goal
Implement **range-based partitioning** in PostgreSQL for a table of grades.

---

## ğŸ“˜ Step 1: Create the Partitioned Table

```sql
CREATE TABLE grades_parts (
  id SERIAL NOT NULL,
  g INT NOT NULL
) PARTITION BY RANGE (g);

```
> ğŸ’¡ The table is partitioned by the column g. No actual ranges are defined yet â€” only the structure.

## ğŸ“˜ Step 2: Create Partition Tables
- We now create 4 partitions manually using the same structure as the parent table.
```sql
CREATE TABLE g0035 (
  LIKE grades_parts including indexes
);

CREATE TABLE g3560 (
  LIKE grades_parts including indexes
);

CREATE TABLE g6080 (
  LIKE grades_parts including indexes
);

CREATE TABLE g80100 (
  LIKE grades_parts including indexes
);
```

> ğŸ“ We're using LIKE to copy the structure from the parent table. No indexes yet â€” weâ€™ll add them later.

## ğŸ“˜ Step 3: Attach Partitions to the Parent Table

Now, attach each partition using the ALTER TABLE ... ATTACH PARTITION command:

```sql
ALTER TABLE grades_parts
ATTACH PARTITION g0035 FOR VALUES FROM (0) TO (35);

ALTER TABLE grades_parts
ATTACH PARTITION g3560 FOR VALUES FROM (35) TO (60);

ALTER TABLE grades_parts
ATTACH PARTITION g6080 FOR VALUES FROM (60) TO (80);

ALTER TABLE grades_parts
ATTACH PARTITION g80100 FOR VALUES FROM (80) TO (100);
```

> ğŸ”— Each gxy partition now contains the specified range of values for g.

## ğŸ“‹ Partition Summary
| Partition Name | Range |
| -------------- | ----- |
| `g_0_35`       | 0â€“34  |
| `g_35_60`      | 35â€“59 |
| `g_60_80`      | 60â€“79 |
| `g_80_100`     | 80â€“99 |

> ğŸ§¹ Note: At this point, all partitions are empty. No data has been inserted yet.

## ğŸ” Table Structure Verification
- You can verify partition attachment like this:
```sql
\d+ g_80_100
```
- Will return:
> Partition of: grades_parts FOR VALUES FROM (80) TO (100)
> ğŸ§  Also note: Neither the parent nor the child tables have indexes yet.

## ğŸ§  Final Notes
- PostgreSQL doesn't auto-create partitions â€” you must define and attach them manually.
- This setup helps optimize queries by limiting access to relevant partitions only.
- You can later add indexes to partitions individually based on your query patterns.

# ğŸ§ª PostgreSQL Partitioning â€“ Inserting & Indexing Demo

---

## ğŸ“¥ Step 4: Insert Data Into the Partitioned Table

Weâ€™ll now insert the **10 million rows** from the original table into the partitioned one:

```sql
INSERT INTO grades_parts
SELECT * FROM grades_original;
```
> âœ… PostgreSQL automatically routes each row to the correct partition based on the value of g.

- How Partition Routing Works
```text
If g = 20 â†’ goes to partition g_0_35

If g = 50 â†’ goes to partition g_35_60

If g = 75 â†’ goes to partition g_60_80

If g = 90 â†’ goes to partition g_80_100
```
> ğŸ’¡ PostgreSQL handles the routing internally â€” no need to write custom logic for it.

## ğŸ“Š Step 5: Verify Data Distribution
- âœ… Total Rows in Parent Table
```sql
SELECT COUNT(*) FROM grades_parts;
-- Output: 10,000,001 (including that extra 1 we inserted earlier)
```
> ğŸ“¦ Check Rows in Each Partition
```sql
SELECT COUNT(*) FROM g_0_35;      -- ~3 million rows
SELECT COUNT(*) FROM g_35_60;     -- ~2 million rows
SELECT COUNT(*) FROM g_60_80;     -- ~2.5 million rows
SELECT COUNT(*) FROM g_80_100;    -- ~2.5 million rows
```
> ğŸ“ˆ These values depend on random distribution, so theyâ€™ll vary slightly every run.

> ğŸ§¾ Validate Partition Boundaries
```sql
SELECT MAX(g) FROM g_0_35;        -- Expect: 34
SELECT MAX(g) FROM g_35_60;       -- Expect: 59
SELECT MAX(g) FROM g_60_80;       -- Expect: 79
SELECT MAX(g) FROM g_80_100;      -- Expect: 99
```
> ğŸ§  PostgreSQL strictly respects the defined ranges for partitions â€” no overlapping or invalid data.

## âš™ï¸ Step 6: Index the Partitioned Table
- Before PostgreSQL 11, indexes had to be manually created on each partition.
- From PostgreSQL 11+, you can simply index the parent table, and PostgreSQL will create the indexes on all partitions automatically.
```sql
CREATE INDEX grades_parts_index
ON grades_parts (g);
```
> âš¡ This creates identical indexes on all child tables under the hood.

## ğŸ” Verify Indexes on Partitions
- Check on g_0_35
```sql
\d g_0_35
```
- You'll see: "grades_parts_index" or similar auto-generated index

- Check on g_35_60
```sql
\d g_35_60
```
- Index is present as well
> ğŸ“¦ Even though the parent table is empty, PostgreSQL manages the index distribution across all partitions.

## ğŸ§  Final Notes
- âœ… Automatic routing + indexing makes partitioning much easier in modern PostgreSQL.
- ğŸ§¹ You donâ€™t need to micromanage each partition â€” Postgres takes care of it.
- âš¡ Always index your partition key if youâ€™ll be filtering by it in queries

# ğŸš€ PostgreSQL Partitioning â€“ Querying, Indexes & Partition Pruning

---

## ğŸ“ˆ Performance Check: Querying the Partitioned Table

### âœ… Run an EXPLAIN ANALYZE on the partitioned table

```sql
EXPLAIN ANALYZE
SELECT COUNT(*) FROM grades_parts WHERE g = 30;
```

- The planner uses Index Scan only on one partition (ğŸ¯ g_0_35)
- Took about 1 second
- Query is efficient â€“ only one small partition is touched!

## ğŸ¤” Comparison with Non-Partitioned Table
```sql
EXPLAIN ANALYZE
SELECT COUNT(*) FROM grades_original WHERE g = 30;
```
- Also uses an index scan
- Similar execution time (~1 sec)

## ğŸ§  Why no big difference?
- Because the system (e.g., your laptop with 16GB RAM) has enough memory to cache the entire index. There's no I/O or memory bottleneck in this small dataset.
- ğŸ§ª What If the Dataset Was Bigger?
```text
Imagine 100M or 500M rows instead of 10M. Index sizes would grow significantly. In that case, memory pressure kicks in â¡ï¸ larger indexes wonâ€™t fit into RAM. Thatâ€™s when partitioning shines: each partition's index is smaller, faster to read from disk, and more cache-friendly.
```

## ğŸ“Š Checking Index Sizes with pg_relation_size
- Use this SQL to find the size of all tables/indexes:

```sql
SELECT relname,
pg_relation_size(oid) AS size_bytes
FROM pg_class
ORDER BY pg_relation_size(oid) DESC;
```
##ğŸ§¾ Example Output (approximate):

| Table / Index          | Size   |
| ---------------------- | ------ |
| `grades_original`      | 362 MB |
| `grades_parts_index`   | 69 MB  |
| `g_0_35` (table)       | 126 MB |
| `g_0_35_g_idx` (index) | 24 MB  |
| `g_35_60_g_idx`        | 18 MB  |
| `g_60_80_g_idx`        | 15 MB  |
| `g_80_100_g_idx`       | 15 MB  |


## ğŸ¯ Observation:
> Partitioned indexes are much smaller (e.g., 24 MB vs. 69 MB)
> âœ… Smaller indexes = faster queries under load.

## ğŸ§  Feature Highlight: Partition Pruning
- What is it?
- Partition pruning tells PostgreSQL to skip irrelevant partitions based on the WHERE clause.

## ğŸ” Check if it's enabled:
```sql
SHOW enable_partition_pruning;
-- Output: on
```
- ğŸ”¥ Turn it OFF and see the problem:
```sql
SET enable_partition_pruning TO off;

EXPLAIN
SELECT COUNT(*) FROM grades_parts WHERE g = 30;
```
## ğŸ˜± Output:
- PostgreSQL scans all partitions:
- g_0_35
- g_35_60
- g_60_80
- g_80_100
> âš ï¸ Even though the value 30 is only in g_0_35, PostgreSQL doesnâ€™t prune unused partitions.

## âœ… Now turn it back ON:
```sql
SET enable_partition_pruning TO on;

EXPLAIN
SELECT COUNT(*) FROM grades_parts WHERE g = 30;
```
> ğŸ§¼ Now PostgreSQL only scans g_0_35, as expected.

## âœ… Final Tips
- ğŸ”§ Always verify that enable_partition_pruning is ON (it's ON by default).
- ğŸ“ Use partitioning when working with large datasets (hundreds of millions of rows).
- ğŸ” Query plans and index sizes become critical for scaling performance.
- ğŸš« If pruning is OFF, PostgreSQL defeats the purpose of partitioning by hitting all partitions.
